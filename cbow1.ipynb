{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cbow1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djrl10/latihan-pertemuan-1/blob/master/cbow1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRVOG5ksmIIH"
      },
      "source": [
        "# AST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RleOOi1gmM6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12fc5807-58ae-43e6-cd41-bfe9b5efac80"
      },
      "source": [
        "!pip3 install javalang\n",
        "import tensorflow as tf\n",
        "import javalang\n",
        "import javalang.tree as jlt\n",
        "from os import walk\n",
        "import pandas as pd\n",
        "from io import StringIO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting javalang\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/e0/12344443d66b9a84844171be90112892a371da6db09866741774b8bc0a2f/javalang-0.13.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from javalang) (1.15.0)\n",
            "Installing collected packages: javalang\n",
            "Successfully installed javalang-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ0nv13TmP5J"
      },
      "source": [
        "types = [jlt.FormalParameter, jlt.BasicType, jlt.PackageDeclaration, jlt.InterfaceDeclaration, jlt.CatchClauseParameter,\n",
        "         jlt.ClassDeclaration, jlt.MethodInvocation, jlt.SuperMethodInvocation, jlt.MemberReference, jlt.SuperMemberReference,\n",
        "         jlt.ConstructorDeclaration, jlt.ReferenceType, jlt.MethodDeclaration, jlt.VariableDeclarator, jlt.IfStatement,\n",
        "         jlt.WhileStatement, jlt.DoStatement, jlt.ForStatement, jlt.AssertStatement, jlt.BreakStatement,\n",
        "         jlt.ContinueStatement, jlt.ReturnStatement, jlt.ThrowStatement, jlt.SynchronizedStatement, jlt.TryStatement,\n",
        "         jlt.SwitchStatement, jlt.BlockStatement, jlt.StatementExpression, jlt.TryResource, jlt.CatchClause,\n",
        "         jlt.CatchClauseParameter, jlt.SwitchStatementCase, jlt.ForControl, jlt.EnhancedForControl]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yhegwUGmPkF"
      },
      "source": [
        "def parse(source):\n",
        "    tokens = javalang.parse.parse(source)\n",
        "    result = []\n",
        "    for path, node in tokens:\n",
        "        if isinstance(node, jlt.PackageDeclaration):\n",
        "            result.append(node.name)\n",
        "            continue\n",
        "        if isinstance(node, jlt.IfStatement):\n",
        "            result.append(\"if\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.InterfaceDeclaration):\n",
        "            result.append(node.name)\n",
        "            continue\n",
        "        if isinstance(node, jlt.ClassDeclaration):\n",
        "            result.append(node.name)\n",
        "            continue\n",
        "        if isinstance(node, jlt.MethodInvocation):\n",
        "            result.append(node.member)\n",
        "            continue\n",
        "        if isinstance(node, jlt.MemberReference):\n",
        "            result.append(node.member)\n",
        "            continue\n",
        "        if isinstance(node, jlt.ConstructorDeclaration):\n",
        "            result.append(node.name)\n",
        "            continue\n",
        "        if isinstance(node, jlt.ReferenceType):\n",
        "            result.append(node.name)\n",
        "            continue\n",
        "        if isinstance(node, jlt.MethodDeclaration):\n",
        "            result.append(node.name)\n",
        "            continue\n",
        "        if isinstance(node, jlt.VariableDeclarator):\n",
        "            result.append(node.name)\n",
        "            continue\n",
        "        if isinstance(node, jlt.ThrowStatement):\n",
        "            result.append(\"throw\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.TryStatement):\n",
        "            result.append(\"try\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.BlockStatement):\n",
        "            result.append(\"block\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.CatchClause):\n",
        "            result.append(\"catch\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.ForStatement):\n",
        "            result.append(\"for\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.AssertStatement):\n",
        "            result.append(\"assert\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.BreakStatement):\n",
        "            result.append(\"break\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.ContinueStatement):\n",
        "            result.append(\"cotinue\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.ReturnStatement):\n",
        "            result.append(\"return\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.ReturnStatement):\n",
        "            result.append(\"return\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.ThrowStatement):\n",
        "            result.append(\"throw\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.SwitchStatement):\n",
        "            result.append(\"switch\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.WhileStatement):\n",
        "            result.append(\"while\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.DoStatement):\n",
        "            result.append(\"do\")\n",
        "            continue\n",
        "        if isinstance(node, jlt.CatchClauseParameter):\n",
        "            result.append(node.types)\n",
        "            continue\n",
        "        if isinstance(node, jlt.BasicType):\n",
        "            result.append(node.name)\n",
        "            continue\n",
        "        if isinstance(node, jlt.SynchronizedStatement):\n",
        "            result.append(\"Synchronized\")\n",
        "            continue\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlM_h4ubmgE4"
      },
      "source": [
        "def Tokenize(dir_name):\n",
        "    df_list = []\n",
        "    df = pd.DataFrame(columns=['File','Token','Defect'])\n",
        "    for (dirpath, dirnames, filenames) in walk(dir_name):\n",
        "        for label in dirnames: \n",
        "            for (dirpath, dirnames, filenames) in walk(dir_name+'/'+label):\n",
        "                for filename in filenames:\n",
        "                    f = open(dir_name+'/'+label+'/'+filename, \"r\")\n",
        "                    f = f.read()\n",
        "                    try:\n",
        "                        p = parse(f)\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                    temp = pd.DataFrame([[filename,p,label]],columns=['File','Token','Defect'])\n",
        "                    df_list.append(temp)\n",
        "                break\n",
        "        break\n",
        "    df = pd.concat(df_list)\n",
        "    df = df.reset_index()\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycy7gzFrmjM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3504dab6-5012-4aeb-bb63-e0421dee805b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwOtrb7Dmloh"
      },
      "source": [
        "Token_camel = Tokenize('/content/drive/My Drive/camel-1.6/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDw0zI4WmoVC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "5e231f06-519d-46de-b42e-64ab7ebc7c54"
      },
      "source": [
        "Token_camel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>File</th>\n",
              "      <th>Token</th>\n",
              "      <th>Defect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>HandleFaultProcessor.java</td>\n",
              "      <td>[org.apache.camel.processor, HandleFaultProces...</td>\n",
              "      <td>Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>XStreamDataFormat.java</td>\n",
              "      <td>[org.apache.camel.dataformat.xstream, XStreamD...</td>\n",
              "      <td>Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>ChoiceProcessor.java</td>\n",
              "      <td>[org.apache.camel.processor, ChoiceProcessor, ...</td>\n",
              "      <td>Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>TransformProcessor.java</td>\n",
              "      <td>[org.apache.camel.processor, TransformProcesso...</td>\n",
              "      <td>Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>DefaultScheduledPollConsumer.java</td>\n",
              "      <td>[org.apache.camel.impl, DefaultScheduledPollCo...</td>\n",
              "      <td>Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>903</th>\n",
              "      <td>0</td>\n",
              "      <td>StreamProducer.java</td>\n",
              "      <td>[org.apache.camel.component.stream, StreamProd...</td>\n",
              "      <td>Non-Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>904</th>\n",
              "      <td>0</td>\n",
              "      <td>Activator.java</td>\n",
              "      <td>[org.apache.camel.osgi, Activator, String, MET...</td>\n",
              "      <td>Non-Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>0</td>\n",
              "      <td>InvokingContextFactory.java</td>\n",
              "      <td>[org.apache.camel.component.cxf.invoker, Invok...</td>\n",
              "      <td>Non-Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>906</th>\n",
              "      <td>0</td>\n",
              "      <td>HttpComponent.java</td>\n",
              "      <td>[org.apache.camel.component.http, HttpComponen...</td>\n",
              "      <td>Non-Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>907</th>\n",
              "      <td>0</td>\n",
              "      <td>SQL.java</td>\n",
              "      <td>[org.apache.camel.builder.sql, RUNTIME, FIELD,...</td>\n",
              "      <td>Non-Defect</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>908 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index  ...      Defect\n",
              "0        0  ...      Defect\n",
              "1        0  ...      Defect\n",
              "2        0  ...      Defect\n",
              "3        0  ...      Defect\n",
              "4        0  ...      Defect\n",
              "..     ...  ...         ...\n",
              "903      0  ...  Non-Defect\n",
              "904      0  ...  Non-Defect\n",
              "905      0  ...  Non-Defect\n",
              "906      0  ...  Non-Defect\n",
              "907      0  ...  Non-Defect\n",
              "\n",
              "[908 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFoy9XeCmqV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680fddc5-1ede-4213-ef32-8e142bcd4469"
      },
      "source": [
        "Token_camel.Token[8]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['org.apache.camel.dataformat.supercsv',\n",
              " 'CsvDataFormat',\n",
              " 'CsvPreference',\n",
              " 'preference',\n",
              " 'STANDARD_PREFERENCE',\n",
              " 'marshal',\n",
              " 'Exchange',\n",
              " 'Object',\n",
              " 'OutputStream',\n",
              " 'OutputStreamWriter',\n",
              " 'out',\n",
              " 'OutputStreamWriter',\n",
              " 'outputStream',\n",
              " 'if',\n",
              " 'object',\n",
              " 'Map',\n",
              " 'block',\n",
              " 'ICsvMapWriter',\n",
              " 'writer',\n",
              " 'CsvMapWriter',\n",
              " 'out',\n",
              " 'preference',\n",
              " 'Map',\n",
              " 'String',\n",
              " 'Object',\n",
              " 'map',\n",
              " 'Map',\n",
              " 'String',\n",
              " 'Object',\n",
              " 'object',\n",
              " 'Set',\n",
              " 'String',\n",
              " 'keys',\n",
              " 'keySet',\n",
              " 'String',\n",
              " 'headers',\n",
              " 'String',\n",
              " 'size',\n",
              " 'toArray',\n",
              " 'headers',\n",
              " 'writeHeader',\n",
              " 'headers',\n",
              " 'write',\n",
              " 'map',\n",
              " 'headers',\n",
              " 'if',\n",
              " 'object',\n",
              " 'block',\n",
              " 'ICsvBeanWriter',\n",
              " 'writer',\n",
              " 'CsvBeanWriter',\n",
              " 'out',\n",
              " 'preference',\n",
              " 'PropertyDescriptor',\n",
              " 'properties',\n",
              " 'getPropertyDescriptors',\n",
              " 'getClass',\n",
              " 'int',\n",
              " 'size',\n",
              " 'length',\n",
              " 'String',\n",
              " 'headers',\n",
              " 'String',\n",
              " 'size',\n",
              " 'for',\n",
              " 'int',\n",
              " 'i',\n",
              " 'i',\n",
              " 'size',\n",
              " 'i',\n",
              " 'block',\n",
              " 'headers',\n",
              " 'i',\n",
              " 'properties',\n",
              " 'i',\n",
              " 'getName',\n",
              " 'writeHeader',\n",
              " 'headers',\n",
              " 'write',\n",
              " 'object',\n",
              " 'headers',\n",
              " 'close',\n",
              " 'unmarshal',\n",
              " 'Object',\n",
              " 'Exchange',\n",
              " 'InputStream',\n",
              " 'ICsvMapReader',\n",
              " 'reader',\n",
              " 'CsvMapReader',\n",
              " 'InputStreamReader',\n",
              " 'inputStream',\n",
              " 'preference',\n",
              " 'String',\n",
              " 'headers',\n",
              " 'getCSVHeader',\n",
              " 'List',\n",
              " 'Map',\n",
              " 'String',\n",
              " 'String',\n",
              " 'list',\n",
              " 'ArrayList',\n",
              " 'Map',\n",
              " 'String',\n",
              " 'String',\n",
              " 'try',\n",
              " 'while',\n",
              " 'block',\n",
              " 'Map',\n",
              " 'String',\n",
              " 'String',\n",
              " 'map',\n",
              " 'read',\n",
              " 'headers',\n",
              " 'if',\n",
              " 'map',\n",
              " 'block',\n",
              " 'break',\n",
              " 'block',\n",
              " 'add',\n",
              " 'map',\n",
              " 'catch',\n",
              " ['EOFException'],\n",
              " 'catch',\n",
              " ['IOException'],\n",
              " 'throw',\n",
              " 'e',\n",
              " 'if',\n",
              " 'size',\n",
              " 'block',\n",
              " 'return',\n",
              " 'get',\n",
              " 'block',\n",
              " 'return',\n",
              " 'list',\n",
              " 'getPreference',\n",
              " 'CsvPreference',\n",
              " 'return',\n",
              " 'preference',\n",
              " 'setPreference',\n",
              " 'CsvPreference',\n",
              " 'preference',\n",
              " 'preference',\n",
              " 'DataFormat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PguH883l7a5"
      },
      "source": [
        "# CBOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulrg-oe57g_2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "8ff97a0b-588c-4e68-b745-f8f9b18e74d4"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import SGD\n",
        "import torch.nn.functional as F\n",
        "\n",
        "CONTEXT_SIZE = 4\n",
        "EMBEDDING_DIM = 300\n",
        "EPOCH = 20\n",
        "VERVOSE = 5\n",
        "\n",
        "corpus_text = Token_camel\n",
        "\n",
        "\n",
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, context_size):\n",
        "        super(CBOW, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.context_size = context_size\n",
        "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_size)\n",
        "        # return vector size will be context_size*2*embedding_size\n",
        "        self.lin1 = nn.Linear(self.context_size * 2 * self.embedding_size, 512)\n",
        "        self.lin2 = nn.Linear(512, self.vocab_size)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        out = self.embeddings(inp).view(1, -1)\n",
        "        out = out.view(1, -1)\n",
        "        out = self.lin1(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.lin2(out)\n",
        "        out = F.log_softmax(out, dim=1)\n",
        "        return out\n",
        "    \n",
        "    def get_word_vector(self, word_idx):\n",
        "        word = Variable(torch.LongTensor([word_idx]))\n",
        "        return self.embeddings(word).view(1, -1)\n",
        "\n",
        "\n",
        "def train_cbow(data, unique_vocab, word_to_idx):\n",
        "    cbow = CBOW(len(unique_vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "    \n",
        "    nll_loss = nn.NLLLoss()  # loss function\n",
        "    optimizer = SGD(cbow.parameters(), lr=0.001)\n",
        "    \n",
        "    print(len(data))\n",
        "    \n",
        "    for epoch in range(EPOCH):\n",
        "        total_loss = 0\n",
        "        for context, target in data:            \n",
        "            inp_var = Variable(torch.LongTensor([word_to_idx[word] for word in context]))\n",
        "            target_var = Variable(torch.LongTensor([word_to_idx[target]]))\n",
        "                        \n",
        "            cbow.zero_grad()\n",
        "            log_prob = cbow(inp_var)\n",
        "            loss = nll_loss(log_prob, target_var)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.data\n",
        "        \n",
        "        if epoch % VERVOSE == 0:\n",
        "            loss_avg = float(total_loss / len(data))\n",
        "            print(\"{}/{} loss {:.2f}\".format(epoch, EPOCH, loss_avg))\n",
        "    return cbow\n",
        "\n",
        "\n",
        "def test_cbow(cbow, unique_vocab, word_to_idx):\n",
        "    # test word similarity\n",
        "    word_1 = unique_vocab[2]\n",
        "    word_2 = unique_vocab[3]\n",
        "    \n",
        "    word_1_vec = cbow.get_word_vector(word_to_idx[word_1])\n",
        "    word_2_vec = cbow.get_word_vector(word_to_idx[word_2])\n",
        "    \n",
        "    word_similarity = (word_1_vec.dot(word_2_vec) / (torch.norm(word_1_vec) * torch.norm(word_2_vec))).data.numpy()[0]\n",
        "    print(\"Similarity between '{}' & '{}' : {:0.4f}\".format(word_1, word_2, word_similarity))\n",
        "\n",
        "\n",
        "def main():\n",
        "    # content processed as context/target\n",
        "    # consider 2*CONTEXT_SIZE as context window where middle word as target\n",
        "    data = list()\n",
        "    for i in range(CONTEXT_SIZE, len(corpus_text) - CONTEXT_SIZE):\n",
        "        data_context = list()\n",
        "        for j in range(CONTEXT_SIZE):\n",
        "            data_context.append(corpus_text[i - CONTEXT_SIZE + j])\n",
        "        \n",
        "        for j in range(1, CONTEXT_SIZE + 1):\n",
        "            data_context.append(corpus_text[i + j])\n",
        "        data_target = corpus_text[i]\n",
        "        data.append((data_context, data_target))\n",
        " \n",
        "    print(\"Some data: \",data[:3])\n",
        "\n",
        "    unique_vocab = list(set(corpus_text))\n",
        "    \n",
        "    # mapping to index\n",
        "    word_to_idx = {w: i for i, w in enumerate(unique_vocab)}\n",
        "\n",
        "    # train model- changed global variable if needed\n",
        "    cbow = train_cbow(data, unique_vocab, word_to_idx)\n",
        "    \n",
        "    # get two words similarity\n",
        "    test_cbow(cbow, unique_vocab, word_to_idx)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0e1169d457f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-0e1169d457f0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mdata_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTEXT_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mdata_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mCONTEXT_SIZE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONTEXT_SIZE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    }
  ]
}